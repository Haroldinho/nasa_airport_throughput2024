{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbdfd75f-83cc-4f2a-b0fd-104adc2add2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# (Optional) Decompress adn Read Hierarchical Data Format (HDF) files \n",
    "The CWAM data has been compressed and save as hdf arrays because of their large files.\n",
    "Although it may not be necessary to interact with these files for the competition, I wanted to provide a few quick steps to extract the data from these files and read their content.\n",
    "It may be useful for visualization or future modeling. \n",
    "\n",
    "It's particularly challenging to interact with these files, as PySpark does not have a native library to automatically read them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac9713df-0191-49fa-9b30-6820fa49f6f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Interacting with the h5.bz2 files\n",
    "## Decompressing the bz2 files\n",
    "## Reading the hdf5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32c676d5-49af-44e4-842d-21b7aceee77c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccf3f257-1548-4d97-a136-9413bc99f56d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "from bz2 import decompress\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdf38eee-f0bc-48ee-8e49-b7b95a7fb7f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/tmp/2022_09_01_23_45_GMT.Forecast.h5.CWAM.h5.bz2', name='2022_09_01_23_45_GMT.Forecast.h5.CWAM.h5.bz2', size=7822871, modificationTime=1730953550000),\n",
       " FileInfo(path='dbfs:/tmp/2022_09_01_23_45_GMT.Forecast.h5.CWAM.h5.compressed', name='2022_09_01_23_45_GMT.Forecast.h5.CWAM.h5.compressed', size=50616880, modificationTime=1730953860000)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b286077c-5f66-4c00-ae04-208026594553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filepath = \"/dbfs/tmp/2022_09_01_23_45_GMT.Forecast.h5.CWAM.h5.bz2\"\n",
    "newfilepath = filepath.replace(\".bz2\", \".compressed\")\n",
    "with open(newfilepath, 'wb') as new_file, bz2.BZ2File(filepath, 'rb') as file:\n",
    "    for data in iter(lambda : file.read(100 * 1024), b''):\n",
    "        new_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3623621-f20c-46f5-85cd-fa6eed833b85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def traverse_datasets(hdf_file):\n",
    "\n",
    "    def h5py_dataset_iterator(g, prefix=''):\n",
    "        for key in g.keys():\n",
    "            item = g[key]\n",
    "            path = f'{prefix}/{key}'\n",
    "            if isinstance(item, h5py.Dataset): # test for dataset\n",
    "                yield (path, item)\n",
    "            elif isinstance(item, h5py.Group): # test for group (go down)\n",
    "                yield from h5py_dataset_iterator(item, path)\n",
    "\n",
    "    for path, _ in h5py_dataset_iterator(hdf_file):\n",
    "        yield path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e506d7a-ff6b-43b4-8b57-f16b3f3c0d3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with h5py.File(newfilepath, 'r') as f:\n",
    "    for dset in traverse_datasets(f):\n",
    "        print('Path:', dset)\n",
    "        print('Shape:', f[dset].shape)\n",
    "        print('Data type:', f[dset].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34e5d95a-c592-4716-a945-474ec28088f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6a0d91e-8ce5-491a-a212-70346f9ce5b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1_read_h5.bza _files",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
